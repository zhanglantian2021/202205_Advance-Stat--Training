#assign Species, ID, and SIteID as factor#
data$Species <- as.factor(data$Species)
data$ID <- as.factor(data$ID)
data$SiteID <- as.factor(data$SiteID)
data2 <- data[c(-2:-11)]
data2<-data2[complete.cases(data2), ] #remove Na's from dataset
dim(data2)
summary(data2)
data<-data2
data2 <- log(data[,2:ncol(data)]) #Log-transform data to insure they are distributed normally
#This gets the natural log ("log") of the data ("data") beginning with column 2 (",2") and
#transforms all columns of the data ("ncol(data)"). If you want to isolate certain columns (eg. HL and WW
#at positions 2 and 3, respectively) then use "log(data[2:3])".
data2 #Read the log transformed data to be sure the data were transformed
species <- data[,1] #Isolate the first column of the csv data file that contains the species so it is not treated as a numeric
data3 <- cbind(species, data2) #Creates a new data frame with OTU's and log-transformed data
data3
pca <- prcomp(data3[,2:ncol(data3)], scale=TRUE) #Perform PCA with scaling.
#Scaling uses the std dev as a scaling factor. After scaling, all data have a std dev of one, therefore data are
#analyzed on the basis of correlations not covariances, as is the case with centering. This way all data are wieghed equally and
#analyzed in proportion to their variance.
#Variables in different units or the same units that have large variances must be scaled so they are comparable.
summary(pca)
scores <- data.frame(species, pca$x[,1:2]) #Create data frame using species and PCA scores from PC1 and PC2
##scores # Use this to view the indiviuual PCA scores if you like. Comment it out if you don't.
write.csv(scores2,"PCA values2.csv", row.names=TRUE) #— This is commented out but use this to print the indiviuual PCA scores.
scores1 <- data.frame(species, pca$x[,2:3]) #Create data frame using species and PCA scores from PC2 and PC3
scores2 <- data.frame(species, pca$x[,3:4]) #Create data frame using species and PCA scores from PC2 and PC3
## Set colors
myCol <- c("blue","gold","darkseagreen2","red","black", "brown1","bisque","skyblue1","coral","green","orange","burlywood", "burlywood4", "skyblue", "blue4", "lightblue1","bisque4","bisque","aquamarine4","aquamarine","deeppink","darkorchid1","yellow","cyan","black","yellow") #Custom color pallette
## Plot PCA scores of PC1 and PC2
a <- ggplot(scores, aes(x=PC1, y=PC2, group=species)) +
theme_bw() + theme(legend.key = element_blank()) +
scale_shape_manual(values=c(21,21,21,21,21,21,21,21,21,21,21,21,21,24,24,24,24,24,24,24,24,23,23,23)) +
scale_fill_manual(values=myCol) +
geom_point(aes(shape=species, color=species, fill=species), size=3, stroke=0.75, color="black") +
labs(x="PC1 (26.7%)", y="PC2 (11.3%)") +
theme(legend.title=element_blank(), axis.text=element_text(size=18), axis.title=element_text(size=20),
legend.text=element_text(face="italic",size=20)) + guides(colour = guide_legend(override.aes = list(size=8)))
plot(a)
## Add if you want to change the background color
theme(panel.background = element_rect(fill = "beige",colour = "darkblue", size = .5, linetype = "solid"),
panel.grid.major = element_line(size = 0.5, linetype = 'solid',colour = "white"),
panel.grid.minor = element_line(size = 0.25, linetype = 'solid',colour = "white"))
## Plot PCA scores of PC2 and PC3
b <- ggplot(scores1, aes(x=PC2, y=PC3, group=species)) + theme_bw() + theme(legend.key = element_blank()) + scale_shape_manual(values=c(21,21,21,16,16,16,16,16,15,16,16,16,15,15,16,15,16,16,15,16,15,16,15,16,15,16)) +
scale_fill_manual(values=myCol) + geom_point(aes(shape=species, color=species, fill=species), stroke=0.5, color="black", size=9) + labs(x="PC2 (15%)", y="PC3 (12%)") +
theme(legend.title=element_blank(), axis.text=element_text(size=18), axis.title=element_text(size=20),
legend.text=element_text(face="italic",size=20))+guides(colour = guide_legend(override.aes = list(size=8)))
plot(b)
## Plot a biplot graph
c <- ggbiplot(pca) + theme_bw() + theme(legend.key = element_blank()) + scale_shape_manual(values=c(21,21,21,21,21,16,16,16,16,15,16,16,16,15,15,16,15,16,16,15,16,15,16,15,16,15,16)) +
scale_fill_manual(values=myCol) + geom_point(aes(shape=species, color=species, fill=species), stroke=0.5, color="black", size=3) + labs(x="PC1 (26.7%)", y="PC2 (11.3%)") +
theme(legend.title=element_blank(), axis.text=element_text(size=18), axis.title=element_text(size=20),
legend.text=element_text(face="italic",size=20))+ guides(colour=guide_legend(override.aes = list(size=8))) + coord_fixed(ratio=1/1)
plot(c)
#checking wether the groups are significant or not on the basis of PC1 and PC2
#PC1
lm1 <- lm(PC1~species,scores)
lm1.contrast <- contrast(emmeans(lm1, specs="species"),method="pairwise")
lm1.contrast
?comparisons
lm1.contrast <- contrast(emmeans(lm1, specs="species"),method="pairwise",p.adjust="Tukey")
lm1.contrast
lm1.contrast <- contrast(emmeans(lm1, specs="species"),method="pairwise",p.adjust="BH")
lm1.contrast
lm1.contrast <- contrast(emmeans(lm1, specs="species"),method="pairwise",comparison="BH")
lm1.contrast
?contrast
lm1.contrast <- contrast(emmeans(lm1, specs="species"),method="pairwise",adjust="BH")
lm1.contrast
lm1.contrast <- contrast(emmeans(lm1, specs="species"),method="pairwise",adjust="Tukey")
lm1.contrast
lm1.contrast <- contrast(emmeans(lm1, specs="species"),method="pairwise",adjust="Bonferroni")
lm1.contrast
?adjust
raw <- read.csv("/Users/kyletomlinson/Dropbox/PROJECTS_WORKING_ON/Ade/Data analysis/final_adjusted_Jin2.csv") #read the data file that is in csv format
summary(raw)
raw$Species <-as.factor(raw$Species)
boxplot(SVL~Species, data = raw, col = c("darkseagreen1", "darksalmon", "thistle2", "tan1"),ylim=c(25,41),xlab="")
boxplot(HL~Species, data = raw, col = c("darkseagreen1", "darksalmon", "thistle2", "tan1"),ylim=c(5,10),xlab="")
quartz()
op<-par(mfrow=c(4,2),oma=c(2,2,2,2),mar=c(3,3,0.8,1),mgp=c(2,1,0.0))
plot(HL~SVL, data = raw, col = c("red", "blue", "darkgreen","orange","purple")[as.numeric(raw$Species)],pch=16)
legend("topleft", inset=.05,# location and inset
bty="n", cex=0.7, # suppress legend box, shrink text 50%
title="Species",
c("Jin1", "Jin2", "montawa","Ngwel","Tony"), fill=c("red","blue","darkgreen","orange","purple"))
plot(HW~SVL, data = raw, col = c("red", "blue", "darkgreen","orange","purple")[as.numeric(raw$Species)],pch=16)
plot(HW~SVL, data = raw, col = c("red", "blue", "darkgreen","orange","purple")[as.numeric(raw$Species)],pch=16)
plot(HW~HL, data = raw, col = c("red", "blue", "darkgreen","orange","purple")[as.numeric(raw$Species)],pch=16)
plot(SnEye~HL, data = raw, col = c("red", "blue", "darkgreen","orange","purple")[as.numeric(raw$Species)],pch=16)
plot(NarEye~HL, data = raw, col = c("red", "blue", "darkgreen","orange","purple")[as.numeric(raw$Species)],pch=16)
plot(SnW~HL, data = raw, col = c("red", "blue", "darkgreen","orange","purple")[as.numeric(raw$Species)],pch=16)
plot(ED~HL, data = raw, col = c("red", "blue", "darkgreen","orange","purple")[as.numeric(raw$Species)],pch=16)
data <- read.csv("/Users/kyletomlinson/Dropbox/PROJECTS_WORKING_ON/Ade/Data analysis/final_adjusted_Jin2.csv") #read the data file that is in csv format
data #Check the data file if you want
data$Species <- as.factor(data$Species)
summary(data)
##########################################################
####################### PERMANOVA ########################
############ formalised tests of significance ############
##########################################################
# before we start, try to recall our data object
data
# remove NA's column (Chin is empty)
data2 <- data[c(-2,-3,-26)]
data2
data2<-data2[complete.cases(data2), ] #remove Na's from dataset
dim(data2)
#split the data frame into Species and Traits
specdata<-subset(data2,select=c(1))
head(specdata)
traits <-subset(data2,select=c(10:25)) #adjusted mensural data and meristic
head(traits)
# 1. are any the sites different?
adonis(formula = traits ~ Species, data = specdata, permutations = 50000, method = "euclidean")
##start copy here for function pairwise.adonis()
#whole piece needs to be run to activat the function
#I choose Benjamini-Hochberg adjustment because we have a large number of groups in the yunnanensis clade
#p.adjust.m ='BH'
pairwise.adonis <- function(x,factors, sim.function = 'vegdist', sim.method = 'bray', p.adjust.m ='Tukey')
{
library(vegan)
co = combn(unique(as.character(factors)),2)
pairs = c()
F.Model =c()
R2 = c()
p.value = c()
for(elem in 1:ncol(co)){
if(sim.function == 'daisy'){
library(cluster); x1 = daisy(x[factors %in% c(co[1,elem],co[2,elem]),],metric=sim.method)
} else{x1 = vegdist(x[factors %in% c(co[1,elem],co[2,elem]),],method=sim.method)}
ad = adonis(x1 ~ factors[factors %in% c(co[1,elem],co[2,elem])] ,permutations = 50000);
pairs = c(pairs,paste(co[1,elem],'vs',co[2,elem]));
F.Model =c(F.Model,ad$aov.tab[1,4]);
R2 = c(R2,ad$aov.tab[1,5]);
p.value = c(p.value,ad$aov.tab[1,6])
}
p.adjusted = p.adjust(p.value,method=p.adjust.m)
sig = c(rep('',length(p.adjusted)))
sig[p.adjusted <= 0.05] <-'.'
sig[p.adjusted <= 0.01] <-'*'
sig[p.adjusted <= 0.001] <-'**'
sig[p.adjusted <= 0.0001] <-'***'
pairw.res = data.frame(pairs,F.Model,R2,p.value,p.adjusted,sig)
print("Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1")
return(pairw.res)
}
##start copy here for function pairwise.adonis()
#whole piece needs to be run to activat the function
#I choose Benjamini-Hochberg adjustment because we have a large number of groups in the yunnanensis clade
#p.adjust.m ='BH'
pairwise.adonis <- function(x,factors, sim.function = 'vegdist', sim.method = 'bray', p.adjust.m ='BH')
{
library(vegan)
co = combn(unique(as.character(factors)),2)
pairs = c()
F.Model =c()
R2 = c()
p.value = c()
for(elem in 1:ncol(co)){
if(sim.function == 'daisy'){
library(cluster); x1 = daisy(x[factors %in% c(co[1,elem],co[2,elem]),],metric=sim.method)
} else{x1 = vegdist(x[factors %in% c(co[1,elem],co[2,elem]),],method=sim.method)}
ad = adonis(x1 ~ factors[factors %in% c(co[1,elem],co[2,elem])] ,permutations = 50000);
pairs = c(pairs,paste(co[1,elem],'vs',co[2,elem]));
F.Model =c(F.Model,ad$aov.tab[1,4]);
R2 = c(R2,ad$aov.tab[1,5]);
p.value = c(p.value,ad$aov.tab[1,6])
}
p.adjusted = p.adjust(p.value,method=p.adjust.m)
sig = c(rep('',length(p.adjusted)))
sig[p.adjusted <= 0.05] <-'.'
sig[p.adjusted <= 0.01] <-'*'
sig[p.adjusted <= 0.001] <-'**'
sig[p.adjusted <= 0.0001] <-'***'
pairw.res = data.frame(pairs,F.Model,R2,p.value,p.adjusted,sig)
print("Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1")
return(pairw.res)
}
##start copy here for function pairwise.adonis()
#whole piece needs to be run to activat the function
#I choose Benjamini-Hochberg adjustment because we have a large number of groups in the yunnanensis clade
#p.adjust.m ='BH'
pairwise.adonis <- function(x,factors, sim.function = 'vegdist', sim.method = 'bray', p.adjust.m ='BH')
{
library(vegan)
co = combn(unique(as.character(factors)),2)
pairs = c()
F.Model =c()
R2 = c()
p.value = c()
for(elem in 1:ncol(co)){
if(sim.function == 'daisy'){
library(cluster); x1 = daisy(x[factors %in% c(co[1,elem],co[2,elem]),],metric=sim.method)
} else{x1 = vegdist(x[factors %in% c(co[1,elem],co[2,elem]),],method=sim.method)}
ad = adonis(x1 ~ factors[factors %in% c(co[1,elem],co[2,elem])] ,permutations = 50000);
pairs = c(pairs,paste(co[1,elem],'vs',co[2,elem]));
F.Model =c(F.Model,ad$aov.tab[1,4]);
R2 = c(R2,ad$aov.tab[1,5]);
p.value = c(p.value,ad$aov.tab[1,6])
}
p.adjusted = p.adjust(p.value,method=p.adjust.m)
sig = c(rep('',length(p.adjusted)))
sig[p.adjusted <= 0.05] <-'.'
sig[p.adjusted <= 0.01] <-'*'
sig[p.adjusted <= 0.001] <-'**'
sig[p.adjusted <= 0.0001] <-'***'
pairw.res = data.frame(pairs,F.Model,R2,p.value,p.adjusted,sig)
print("Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1")
return(pairw.res)
}
#please remember you need to run the function code below to check do this
pairwise.adonis(traits,specdata[,1])
head(traits)
head(traits)
head(specdata)
#please remember you need to run the function code below to check do this
pairwise.adonis(traits,specdata[,1])
#please remember you need to run the function code below to check do this
pairwise.adonis(traits,specdata$Species)
setwd("/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2022/Lectures/Lesson 2 Generalised linear models")
#load the data and look at its structure
mydata <- read.csv("binary.csv",header=T,sep=" ")
## view the first few rows of the data
head(mydata)
summary(mydata)
str(mydata)
#NOTE: R is reading Rank as a numeric. We need to convert it to a factor. (In general, ALWAYS check the summary() statement or str() statment of imported data to make sure that your data columns are of the correct type.)
mydata$rank <- as.factor(mydata$rank)
#recheck the data
summary(mydata)
str(mydata)
mylogit <- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial")
summary(mylogit)
anova(mylogit,test='Chisq')
par(mfrow=c(2,2)); plot(mylogit)
# perform an overdispersion test (recall we compare residual chi-sq to the residual degrees of freedom)
chisq <- sum(resid(mylogit, type='pearson')^2)
chisq/df.residual(mylogit) ## close to 1; no overdispersion problem
library(arm)
?binnedplot
x <- predict(mylogit)
y <- resid(mylogit)
binnedplot(x,y)
null.logit <- glm(admit ~ 1, data = mydata, family = "binomial")
summary(null.logit)
dim(mydata)
anova(null.logit,mylogit,test="Chisq")
#now check the deviance explained by each parameter in the model
anova(mylogit,test="Chisq")
summary(mylogit)
mydata <- read.csv("binary.csv",header=T,sep=" ")
summary(mydata)
mydata$rank <- as.factor(mydata$rank)
glm1 <- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial")
summary(glm1)
glm2 <- glm(admit ~ gpa+rank, data = mydata, family = "binomial")
summary(glm2)
anova(glm1,glm2,test="Chisq")
AIC(glm1,glm2)
mydata <- read.csv("ceb.csv",header=T)
options(na.action = "na.fail")
#supply same maximum model
glm1 <- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial")
mydata <- read.csv("binary.csv",header=T,sep=" ")
summary(mydata)
mydata$rank <- as.factor(mydata$rank)
glm1 <- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial")
summary(glm1)
glm2 <- glm(admit ~ gpa+rank, data = mydata, family = "binomial")
summary(glm2)
anova(glm1,glm2,test="Chisq")
AIC(glm1,glm2)
library(MuMIn)
options(na.action = "na.fail")
#supply same maximum model
glm1 <- glm(admit ~ gre+gpa+rank, data = mydata, family = "binomial")
#run dredge function, which gets all subset models and ranks them highest to lowest
ms1 <- dredge(glm1)
summary(ms1)
mod.ave <- model.avg(ms1, subset = delta < 10)
summary(mod.ave)
ms1
aphid2 <- read.csv('/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2022/Lectures/Lesson 2 Generalised linear models/AphidData2.csv', h=T)
#check out the data
summary(aphid2) #two treatments and counts of aphids. typical poisson data
dim(aphid2)
head(aphid2)
str(aphid2)
aphid2$trt <- as.factor(aphid2$trt)
mod1 <- glm(n.aphids~trt, data=aphid2, family=poisson)
summary(mod1)
par(mfrow=c(2,2)); plot(mod1)
#check for overdispersion formally
chisq <- sum(resid(mod1, type='pearson')^2)
chisq/df.residual(mod1) ## much greater than 1
## significantly so?
1-pchisq(chisq, df.residual(mod1)) ## Very significant
#include library to run the dispersiontest
library(AER)
#from the chisq residuals estimate, we know its overdispersion, so set up the test to  check for this
dispersiontest(mod1,alternative = "greater")
mod.qp <- glm(n.aphids~trt, data=aphid2, family=quasipoisson(link=log))
coef(mod.qp)
coef(mod1)
quartz()
par(mfrow=c(2,2)); plot(mod1)
quartz()  #windows people, please use "windows()" here
par(mfrow=c(2,2)); plot(mod.qp)
## looks similar to mod1
## only thing that changes is the scaling (bottom right plot)
summary(mod.qp)
summary(mod1)
anova(mod.qp, test='Chisq')
sum(resid(mod1, type='pearson')^2)/df.residual(mod1)
sum(resid(mod.qp, type='pearson')^2)/df.residual(mod.qp) ## the same
summary(mod1)$dispersion
summary(mod.qp)$dispersion ## different between models
#but look what has happened to the standard errors of the model outputs
coef(summary(mod1))
coef(summary(mod.qp))
#you can also test the significance of the quasipoisson model using ANOVA
anova(mod.qp, test='F')
#ok lets make some predictions quickly..
fit=fitted.values(mod.qp)
yrep<-as.data.frame(fit)
yrep$trt<-aphid2$trt
library(ggplot2)
ggplot()+
geom_boxplot(aes(x = aphid2$trt, y=log(aphid2$n.aphids)))+
geom_point(aes(x = aphid2$trt, y=log(aphid2$n.aphids)))
#negative binomial
library(MASS)
mod.nb <- glm.nb(n.aphids~trt, data=aphid2)
summary(mod.nb)
quartz(); par(mfrow=c(2,2));plot(mod.nb)
quartz(); par(mfrow=c(2,2));plot(mod.nb)
#CMP
library(COMPoissonReg)
mod.CMP <- glm.cmp(n.aphids~trt, data=aphid2)
summary(mod.CMP)
#https://www.rdocumentation.org/packages/COMPoissonReg/versions/0.7.0/topics/COMPoissonReg-package
plot(mod.CMP)
#compare coefficients of models
coef(mod1)
coef(mod.qp)
coef(mod.nb)
coef(mod.CMP)
#compare AIC values of models
AIC(mod1); AIC(mod.nb); AIC(mod.CMP)
summary(mod.CMP)
summary(aphid2)
?glm.cmp
#compare AIC values of models
AIC(mod1); AIC(mod.nb); AIC(mod.CMP)
coef(mod.nb)
summary(mod.nb)
summary(mod.CMP)
?summary.cmp
resids <- resids(mod.CMP)
str(mod.CMP)
setwd("/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2022/Lectures/Lesson 2 Generalised linear models")
aphid2 <- read.csv('/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2022/Lectures/Lesson 2 Generalised linear models/AphidData2.csv', h=T)
#check out the data
summary(aphid2) #two treatments and counts of aphids. typical poisson data
dim(aphid2)
head(aphid2)
str(aphid2)
aphid2$trt <- as.factor(aphid2$trt)
mod1 <- glm(n.aphids~trt, data=aphid2, family=poisson)
summary(mod1)
par(mfrow=c(2,2)); plot(mod1)
#check for overdispersion formally
chisq <- sum(resid(mod1, type='pearson')^2)
chisq/df.residual(mod1) ## much greater than 1
## significantly so?
1-pchisq(chisq, df.residual(mod1)) ## Very significant
#include library to run the dispersiontest
library(AER)
#from the chisq residuals estimate, we know its overdispersion, so set up the test to  check for this
dispersiontest(mod1,alternative = "greater")
mod.qp <- glm(n.aphids~trt, data=aphid2, family=quasipoisson(link=log))
coef(mod.qp)
coef(mod1)
quartz()
par(mfrow=c(2,2)); plot(mod1)
quartz()  #windows people, please use "windows()" here
par(mfrow=c(2,2)); plot(mod.qp)
## looks similar to mod1
## only thing that changes is the scaling (bottom right plot)
summary(mod.qp)
summary(mod1)
anova(mod.qp, test='Chisq')
sum(resid(mod1, type='pearson')^2)/df.residual(mod1)
sum(resid(mod.qp, type='pearson')^2)/df.residual(mod.qp) ## the same
summary(mod1)$dispersion
summary(mod.qp)$dispersion ## different between models
#but look what has happened to the standard errors of the model outputs
coef(summary(mod1))
coef(summary(mod.qp))
#you can also test the significance of the quasipoisson model using ANOVA
anova(mod.qp, test='F')
#ok lets make some predictions quickly..
fit=fitted.values(mod.qp)
yrep<-as.data.frame(fit)
yrep$trt<-aphid2$trt
library(ggplot2)
ggplot()+
geom_boxplot(aes(x = aphid2$trt, y=log(aphid2$n.aphids)))+
geom_point(aes(x = aphid2$trt, y=log(aphid2$n.aphids)))
#negative binomial
library(MASS)
mod.nb <- glm.nb(n.aphids~trt, data=aphid2)
summary(mod.nb)
quartz(); par(mfrow=c(2,2));plot(mod.nb)
#CMP
library(COMPoissonReg)
mod.CMP <- glm.cmp(n.aphids~trt, data=aphid2)
summary(mod.CMP)
#compare coefficients of models
coef(mod1)
install.packages("mpcmp")
library(mpcmp)
mod.CMP <- glm.cmp(n.aphids~trt, data=aphid2)
summary(mod.CMP)
mod.CMP <- glm.cmp(n.aphids~trt, data=aphid2)
summary(mod.CMP)
quartz(); par(mfrow=c(2,2));plot(mod.nb)
setwd("/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2022/Lectures/Lesson 2 Generalised linear models")
library(ggplot2)
aphid2 <- read.csv('/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2022/Lectures/Lesson 2 Generalised linear models/AphidData2.csv', h=T)
#check out the data
summary(aphid2) #two treatments and counts of aphids. typical poisson data
dim(aphid2)
head(aphid2)
str(aphid2)
aphid2$trt <- as.factor(aphid2$trt)
mod1 <- glm(n.aphids~trt, data=aphid2, family=poisson)
summary(mod1)
par(mfrow=c(2,2)); plot(mod1)
#check for overdispersion formally
chisq <- sum(resid(mod1, type='pearson')^2)
chisq/df.residual(mod1) ## much greater than 1
## significantly so?
1-pchisq(chisq, df.residual(mod1)) ## Very significant
#include library to run the dispersiontest
library(AER)
#from the chisq residuals estimate, we know its overdispersion, so set up the test to  check for this
dispersiontest(mod1,alternative = "greater")
mod.qp <- glm(n.aphids~trt, data=aphid2, family=quasipoisson(link=log))
coef(mod.qp)
coef(mod1)
quartz()
## looks similar to mod1
## only thing that changes is the scaling (bottom right plot)
summary(mod.qp)
summary(mod1)
anova(mod.qp, test='Chisq')
sum(resid(mod1, type='pearson')^2)/df.residual(mod1)
sum(resid(mod.qp, type='pearson')^2)/df.residual(mod.qp) ## the same
summary(mod1)$dispersion
summary(mod.qp)$dispersion ## different between models
#but look what has happened to the standard errors of the model outputs
coef(summary(mod1))
coef(summary(mod.qp))
#you can also test the significance of the quasipoisson model using ANOVA
anova(mod.qp, test='F')
#ok lets make some predictions quickly..
fit=fitted.values(mod.qp)
yrep<-as.data.frame(fit)
yrep$trt<-aphid2$trt
library(ggplot2)
ggplot()+
geom_boxplot(aes(x = aphid2$trt, y=log(aphid2$n.aphids)))+
geom_point(aes(x = aphid2$trt, y=log(aphid2$n.aphids)))
#negative binomial
library(MASS)
mod.nb <- glm.nb(n.aphids~trt, data=aphid2)
summary(mod.nb)
quartz(); par(mfrow=c(2,2));plot(mod.nb)
#CMP
library(mpcmp)
mod.CMP <- glm.cmp(n.aphids~trt, data=aphid2)
summary(mod.CMP)
quartz(); par(mfrow=c(2,2));plot(mod.nb)
#compare coefficients of models
coef(mod1)
coef(mod.qp)
coef(mod.nb)
coef(mod.CMP)
#compare AIC values of models
AIC(mod1); AIC(mod.nb); AIC(mod.CMP)
#negative binomial
library(MASS)
mod.nb <- glm.nb(n.aphids~trt, data=aphid2)
summary(mod.nb)
quartz(); par(mfrow=c(2,2));plot(mod.nb)
#CMP
library(COMPoissonReg)
library(mpcmp)
mod.CMP <- glm.cmp(n.aphids~trt, data=aphid2)
summary(mod.CMP)
quartz(); par(mfrow=c(2,2));plot(mod.nb)
#compare coefficients of models
coef(mod1)
coef(mod.qp)
coef(mod.nb)
coef(mod.CMP)
#compare AIC values of models
AIC(mod1); AIC(mod.nb); AIC(mod.CMP)
