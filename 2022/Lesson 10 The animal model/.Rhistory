bayes_R2(model_Flog)
#output table including conditional and marginal R2
library(sjPlot)
tab_model(model_Flog, show.intercept = T, show.r2 = TRUE,
transform = NULL,show.re.var=T)
#Posterior predictive distribution: good data fitting
pp_check(model_Flog, nsamples =100)
?pp_check
#Posterior predictive fit: good data fitting
pp_check(model_Flog, type = "scatter_avg_grouped", group = "Function") +
geom_abline(intercept = 0, slope = 1 , color = "red", lty = 2)
####More check if needed to improve models (more can be found)
#Effective number of independent simulation draws: good model running
mcmc_plot(model_Flog, type = "neff")
#Autocorrelation
library(rstan)
stan_ac(model_Flog$fit)
#Interclass Correlation Coefficient: variance partition coefficient
library(performance)
library(dplyr)
icc(model_Flog) %>% print(prob = .95, digits = 3)
#Reduced model without random phylogeny
model_Flog2 <-brm(Dlog~Function+(1|Species),
data = bark2, family = gaussian(), sample_prior = TRUE,
iter = 20000,warmup = 10000, chains = 4, cores = 4,
thin = 10, save_all_pars = TRUE,seed=T,
control=list(adapt_delta=0.99))
#plot the posterior fixed effect estimates with credible intervals over the data
plot(conditional_effects(model_Flog), points = TRUE)
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(model_Flog, pars = c("^b_", "^sd_"))
debark <- read.csv("bark/debarking.csv", header = TRUE, sep = ",", row.names = NULL)
summary(debark)
debark$Species <- as.factor(debark $Species)
debark $Family <- as.factor(debark $Family)
debark $Strategy <- as.factor(debark $Strategy)
summary(debark)
n1<-unique(phylo$tip.label)
str(n1)
debark2 <- debark[debark$Species %in% n1,]
dim(debark)
dim(debark2)
length(unique(debark2$Species))
#so, second reduce tree to match common taxa with data
n2<-unique(debark2$Species)
phylo3<-keep.tip(phylo,phylo$tip.label[match(n2, phylo$tip.label)])
summary(phylo3)
#so, second reduce tree to match common taxa with data
n2<-unique(debark2$Species)
phylo3<-keep.tip(phylo,phylo$tip.label[match(n2, phylo$tip.label)])
summary(phylo3)
#make the covariance matrix from the phylogeny
phylo_cor3 <- ape::vcv.phylo(phylo3)
summary(phylo_cor3)
#make an additional factor to reference the species in the phylogeny
debark2$phylo3 <- debark2$Species
summary(debark2)
#OK now we can run the model
#i want to compare the beta model against the binomial model
debark2$Prop.S.int <- as.integer(debark2$Prop.S*10)
summary(debark2)
#so lets force the percentage data into proportional data
debark2$Prop.S.01=as.numeric(debark2$Prop.S.int)/1000
m_debark_beta <-brm(Prop.S.01~Strategy+(1|phylo3),
cov_ranef = list(phylo3 = phylo_cor3),
data = debark2, family = Beta(), sample_prior = TRUE,
iter = 2000,warmup = 1000, chains = 4, cores = 4,
thin = 10, save_all_pars = TRUE, seed = T,
control=list(adapt_delta=0.95, max_treedepth=15))
summary(m_debark_beta)
?Bulk_ESS
summary(m_debark_beta)
debark2$Prop.S.int
m_debark_binom <-brm(Prop.S.int|trials(1000)~Strategy+(1|phylo3),
cov_ranef = list(phylo3 = phylo_cor3),
data = debark2, family = binomial(), sample_prior = TRUE,
iter = 2000,warmup = 1000, chains = 4, cores = 4,
thin = 10, save_all_pars = TRUE, seed = T,
control=list(adapt_delta=0.95, max_treedepth=15))
library(MLmetrics)
library(MuMIn)
library(ggplot2)
summary(debark2)
#R-squared: variance explained by model
bayes_R2(m_debark_beta)
#R-squared: variance explained by model
bayes_R2(m_debark_binom)
#Posterior predictive intervals: good data fitting
pp_check(m_debark_beta, type = "intervals_grouped", group = "Strategy")
quartz()
pp_check(m_debark_binom, type = "intervals_grouped", group = "Strategy")
#Posterior predictive fit: good data fitting
pp_check(m_debark_beta, type = "scatter_avg_grouped", group = "Strategy") +
geom_abline(intercept = 0, slope = 1 , color = "red", lty = 2)
pp_check(m_debark_binom, type = "scatter_avg_grouped", group = "Strategy") +
geom_abline(intercept = 0, slope = 1 , color = "red", lty = 2)
#get fitted values
Yrep.beta<- as.data.frame(fitted (m_debark_beta))
Yrep.binom<- as.data.frame(fitted (m_debark_binom))
obs <- debark2$Prop.S.01
y.beta <- Yrep.beta$Estimate
y.binom <- Yrep.binom$Estimate/1000
comb <- data.frame(obs,y.beta,y.binom)
ggplot(data=comb, aes(x=obs, y=y.beta)) + geom_point(col="red")+
geom_point(data=comb,aes(x=obs, y=y.binom),
stat='identity')
ggplot(data=comb, aes(x=obs, y=y.beta)) + geom_point(col="red")
#Posterior predictive intervals: good data fitting
pp_check(m_debark_beta, type = "intervals_grouped", group = "Strategy")
#Posterior predictive intervals: good data fitting
pp_check(model_Flog, type = "intervals_grouped", group = "Function")
#Posterior predictive distribution: good data fitting
pp_check(model_Flog, nsamples =100)
model_Flog <- readRDS("bark/Dlog_Int_Phyl_Spec.rds")
#use summary() to check convergence of the model (Rhat and ESS) and the parameter estimates (coefficients and betas)
summary(model_Flog)
#now look at the posterior distributions generated for each estimate and the chain value (this should form nice horizontal bands called "hairy caterpillars"; if not flat then sampling possibly insufficient or model underspecified)
plot(model_Flog, N = 6, ask = FALSE)
#plot the posterior fixed effect estimates with credible intervals over the data
plot(conditional_effects(model_Flog), points = TRUE)
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(model_Flog, pars = c("^b_", "^sd_"))
hyp <- "(sd_phylo2__Intercept^2)/ (sd_phylo2__Intercept^2 + sd_Species__Intercept^2 + sigma^2) = 0"
(hyp <- hypothesis(model_Flog, hyp, class = NULL))
#R-squared: variance explained by model
bayes_R2(model_Flog)
m_debark_beta <- readRDS("bark/debark_squirrel_beta.rds")
#R-squared: variance explained by model
bayes_R2(m_debark_beta)
#Posterior predictive intervals: good data fitting
pp_check(m_debark_beta, type = "intervals_grouped", group = "Strategy")
#plot the model
ggplot(data=comb, aes(x=obs, y=y.beta)) + geom_point(col="red")
plot(y.beta~obs,data=comb,col="red")
abline(a=0,b=1,col="black")
#RMSPE tests
RMSPE(y_pred=y.beta,y_true=obs)
library(MLmetrics)
library(MuMIn)
#####
#get fitted values
Yrep.beta<- as.data.frame(fitted (m_debark_beta))
obs <- debark2$Prop.S.01
y.beta <- Yrep.beta$Estimate
summary(Yrep.beta)
y.beta <- Yrep.beta$Estimate
comb <- data.frame(obs,y.beta)
ggplot(data=comb, aes(x=obs, y=y.beta)) + geom_point(col="red")
plot(y.beta~obs,data=comb,col="red")
abline(a=0,b=1,col="black")
ggplot(data=comb, aes(x=obs, y=y.beta)) + geom_point(col="red")
plot(y.beta~obs,data=comb,col="red")
par(mfrow=c(1,1))
plot(y.beta~obs,data=comb,col="red")
abline(a=0,b=1,col="black")
#RMSPE tests
RMSPE(y_pred=y.beta,y_true=obs)
#Posterior predictive intervals: good data fitting
pp_check(m_debark_beta, type = "intervals_grouped", group = "Strategy")
m_debark_beta <- readRDS("bark/debark_squirrel_beta.rds")
summary(debark2)
summary(m_debark_beta)
#Posterior predictive intervals: good data fitting
pp_check(m_debark_beta, type = "intervals_grouped", group = "Strategy")
#now look at the posterior distributions generated for each estimate and the chain value (this should form nice horizontal bands called "hairy caterpillars"; if not flat then sampling possibly insufficient or model underspecified)
plot(m_debark_beta, N = 6, ask = FALSE)
#plot the posterior fixed effect estimates with credible intervals over the data
plot(conditional_effects(m_debark_beta), points = TRUE)
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(m_debark_beta, pars = c("^b_", "^sd_"))
obs
#get fitted values
Yrep.Flog<- as.data.frame(fitted (model_Flog))
summary(Yrep.Flog)
Yrep.Flog2<- as.data.frame(fitted (model_Flog2))
obs <- bark2$Dlog
y.fit.Flog <- Yrep.Flog$Estimate
y.fit.Flog2 <- Yrep.Flog2$Estimate
obs <- bark2$Dlog
comb <- data.frame(obs,y.fit.Flog,y.fit.Flog2)
#RMSPE tests
RMSPE(y_pred=y.fit.Flog,y_true=obs)
RMSPE(y_pred=y.fit.Flog2,y_true=obs)
####Model selection
#Leave-one-out cross-validation: compare models performance
loo(model_Flog,model_Flog2,reloo=F)
?loo_compare
?loo
#using brms
# Setting up data
y1 <- c(1, 1, 1, 1, 1, 0, 1, 0, 0, 0)
y2 <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 0)
data_list <- list(y1 = y1, y2 = y2, n1 = length(y1), n2 = length(y2))
data <- data.frame('response' = c(y1,y2),
'name'=c(rep('baby',length(y1)),rep('dog',length(y2))))
# visualize the data
ggplot(data, aes(x = name, y = response)) +
geom_point() +
geom_jitter()
summary(data)
## generalized linear model
glm1 <- glm(response ~ name, data = data, family = "binomial")
summary(glm1)
model_brms <- brm(response~name,
data = data,
family = bernoulli(),
chains = 4, # default settings,
iter = 2000, # default settings,
warmup = 1000, # default settings,
thin = 1, # default setting, no thinning. Must be a positive integer. Set thin > 1 to save memory and computation time if iter is large.
)
####Model selection
#Leave-one-out cross-validation: compare models performance
loo(model_Flog,model_Flog2,reloo=F)
summary(model_brms)
## plot the model for diagnostics.
plot(model_brms)
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(model_Flog, pars = c("^b_", "^sd_"))
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(model_Flog)
####Model selection
#Leave-one-out cross-validation: compare models performance
loo(model_Flog,model_Flog2,reloo=F)
help('pareto-k-diagnostic')
loo_compare(model_Flog,model_Flog2)
?loo_compare
loo_compare(model_Flog,model_Flog2,criterion=c("loo","waic"))
loo_compare(model_Flog,model_Flog2,criterion=c("loo"))
loo_compare(model_Flog,model_Flog2,criterion="loo")
loo_compare(model_Flog,model_Flog2,criterion="waic")
library(sjPlot)
tab_model(model_brms)
## More informative priors
# get the default priors
prior_summary(model_brms)
model_brms_1 <- brm(response~name,
data = data,
family = bernoulli(),
chains = 4, # default settings,
iter = 2000, # default settings,
warmup = 1000, # default settings,
thin = 1, # default setting
prior = prior(normal(1,1), class="b",coef="namedog")
)
prior_summary(model_brms_1)
summary(model_brms_1)
summary(model_brms)
library(brms)
library(ggplot2)
library(ape)
library(caper)
library(sjPlot)
library(MLmetrics)
library(MuMIn)
#################################################
#### load trait data #####
#################################################
setwd("/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2021/Lectures/Lesson 10 The animal model")
# database with the corrected data
bark <- read.csv("bark/bark_nutrition.csv", header = TRUE, sep = ",", row.names = NULL)
summary(bark)
bark$Species <- as.factor(bark$Species)
bark$Family <- as.factor(bark$Family)
bark$Month <- as.factor(bark$Month)
bark$Function <- as.factor(bark$Function)
summary(bark)
length(unique(bark$Species)) #53 species
phylo <- read.tree("/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2021/Lectures/Lesson 10 The animal model/bark/scenario.2_run.1.tre")
plot(phylo)
summary(phylo)  #31 species
dim(bark)
# there are no polytomies
is.binary.tree(phylo) #TRUE
# check tree is ultrametric
is.ultrametric(phylo) # TRUE
#try comparative data
combine<-comparative.data(phylo,bark,Species,vcv=TRUE,na.omit=F)
unique(phylo$tip.label)
#different route
#first reduce data to list of common taxa with tree
n1<-unique(phylo$tip.label)
str(n1)
bark2 <- bark[bark$Species %in% n1,]
dim(bark)
dim(bark2)
length(unique(bark2$Species)) #only 27, less than the tree
#so, second reduce tree to match common taxa with data
n2<-unique(bark2$Species)
phylo2<-keep.tip(phylo,phylo$tip.label[match(n2, phylo$tip.label)])
summary(phylo2) #now 27 tips, which match the ones you made above
#make the covariance matrix from the phylogeny
phylo_cor <- ape::vcv.phylo(phylo2)
summary(phylo_cor)
dim(phylo_cor)
#make an additional factor to reference the species in the phylogeny
bark2$phylo2 <- bark2$Species
par(mfrow=c(1,3))
plot(density((bark2$D)))
plot(density(sqrt(bark2$D)))
plot(density(log(bark2$D)))
bark2 $Dlog=log(bark2 $D)
summary(bark2)
#lets run the model using
set.seed(1)
model_Flog <-brm(Dlog~Function+(1|phylo2)+(1|Species),
cov_ranef = list(phylo2 = phylo_cor),
data = bark2, family = gaussian(link="identity"), sample_prior = TRUE,
iter = 10000,warmup = 5000, chains = 4, cores = 4,
thin = 10, save_all_pars = TRUE,seed=T,
control=list(adapt_delta=0.99))
#use summary() to check convergence of the model (Rhat and ESS) and the parameter estimates (coefficients and betas)
summary(model_Flog)
#now look at the posterior distributions generated for each estimate and the chain value (this should form nice horizontal bands called "hairy caterpillars"; if not flat then sampling possibly insufficient or model underspecified)
plot(model_Flog, N = 6, ask = FALSE)
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(model_Flog, pars = c("^b_", "^sd_"))
#estimate proportional variation explained by phylogenetic signal
hyp <- "(sd_phylo2__Intercept^2)/ (sd_phylo2__Intercept^2 + sd_Species__Intercept^2 + sigma^2) = 0"
(hyp <- hypothesis(model_Flog, hyp, class = NULL))
#R-squared: variance explained by model
bayes_R2(model_Flog)
#output table including conditional and marginal R2
library(sjPlot)
tab_model(model_Flog, show.intercept = T, show.r2 = TRUE,
transform = NULL,show.re.var=T)
#Posterior predictive distribution: good data fitting
pp_check(model_Flog, nsamples =100)
#what follows are some tests evaluating the performance of the analysis
library(performance)
#Posterior predictive distribution: good data fitting
pp_check(model_Flog, nsamples =100)
#output table including conditional and marginal R2
library(sjPlot)
#Posterior predictive distribution: good data fitting
pp_check(model_Flog, nsamples =100)
#lets run the model using
set.seed(1)
model_Flog <-brm(Dlog~Function+(1|phylo2)+(1|Species),
cov_ranef = list(phylo2 = phylo_cor),
data = bark2, family = gaussian(link="identity"), sample_prior = TRUE,
iter = 10000,warmup = 5000, chains = 4, cores = 4,
thin = 10, save_all_pars = TRUE,seed=T,
control=list(adapt_delta=0.99))
#Posterior predictive distribution: good data fitting
pp_check(model_Flog, nsamples =100)
#Posterior predictive intervals: good data fitting
pp_check(model_Flog, type = "intervals_grouped", group = "Function")
pp_check(model_Flog, type = "scatter_avg_grouped", group = "Function") +
geom_abline(intercept = 0, slope = 1 , color = "red", lty = 2)
model_Flog2 <-brm(Dlog~Function+(1|Species),
data = bark2, family = gaussian(), sample_prior = TRUE,
iter = 20000,warmup = 10000, chains = 4, cores = 4,
thin = 10, save_all_pars = TRUE,seed=T,
control=list(adapt_delta=0.99))
summary(model_Flog2)
####Model selection
#Leave-one-out cross-validation: compare models performance
loo(model_Flog,model_Flog2)
#get fitted values
Yrep.Flog<- as.data.frame(fitted (model_Flog))
summary(Yrep.Flog)
y.fit.Flog <- Yrep.Flog$Estimate
Yrep.Flog2<- as.data.frame(fitted (model_Flog2))
y.fit.Flog2 <- Yrep.Flog2$Estimate
obs <- bark2$Dlog
comb <- data.frame(obs,y.fit.Flog,y.fit.Flog2)
summary(comb)
#RMSPE tests
RMSPE(y_pred=y.fit.Flog,y_true=obs)
RMSPE(y_pred=y.fit.Flog2,y_true=obs)
debark <- read.csv("bark/debarking.csv", header = TRUE, sep = ",", row.names = NULL)
summary(debark)
debark$Species <- as.factor(debark $Species)
debark $Family <- as.factor(debark $Family)
debark $Strategy <- as.factor(debark $Strategy)
summary(debark)
n1<-unique(phylo$tip.label)
str(n1)
debark2 <- debark[debark$Species %in% n1,]
dim(debark)
dim(debark2)
length(unique(debark2$Species))
#so, second reduce tree to match common taxa with data
n2<-unique(debark2$Species)
phylo3<-keep.tip(phylo,phylo$tip.label[match(n2, phylo$tip.label)])
summary(phylo3)
#make the covariance matrix from the phylogeny
phylo_cor3 <- ape::vcv.phylo(phylo3)
summary(phylo_cor3)
#make an additional factor to reference the species in the phylogeny
debark2$phylo3 <- debark2$Species
#so lets force the percentage data into proportional data
debark2$Prop.S.01=as.numeric(debark2$Prop.S.int)/100
#OK now we can run the model
#i want to compare the beta model against the binomial model
debark2$Prop.S.int <- as.integer(debark2$Prop.S*10)
summary(debark2)
#so lets force the percentage data into proportional data
debark2$Prop.S.01=as.numeric(debark2$Prop.S.int)/1000
summary(debark2$Prop.S.01)
dim(debark2)
summary(phylo_cor3)
summary(phylo3)
dim(debark2)
m_debark_beta <-brm(Prop.S.01~Strategy+(1|phylo3),
cov_ranef = list(phylo3 = phylo_cor3),
data = debark2, family = Beta(), sample_prior = TRUE,
iter = 2000,warmup = 1000, chains = 4, cores = 4,
thin = 1, save_all_pars = TRUE, seed = T,
control=list(adapt_delta=0.95, max_treedepth=15))
summary(m_debark_beta)
summary(debark2)
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(m_debark_beta)
library(brms)
library(ggplot2)
library(ape)
library(caper)
library(sjPlot)
library(MLmetrics)
library(MuMIn)
library(rstan)
# database with the corrected data
bark <- read.csv("bark/bark_nutrition.csv", header = TRUE, sep = ",", row.names = NULL)
summary(bark)
bark$Species <- as.factor(bark$Species)
bark$Family <- as.factor(bark$Family)
bark$Month <- as.factor(bark$Month)
bark$Function <- as.factor(bark$Function)
summary(bark) #note that there are multiple individuals per species!!! (not possible to have this in many comparative packages)
dim(bark)
length(unique(bark$Species)) #53 species
phylo <- read.tree("/Users/kyletomlinson/Dropbox/Teaching/XTBG advanced stats 2021/Lectures/Lesson 10 The animal model/bark/scenario.2_run.1.tre")
plot(phylo)
summary(phylo)  #31 species
# there are no polytomies
is.binary.tree(phylo) #TRUE
# check tree is ultrametric
is.ultrametric(phylo) # TRUE
#try comparative data
combine<-comparative.data(phylo,bark,Species,vcv=TRUE,na.omit=F)
#different route
#first reduce data to list of common taxa with tree
n1<-unique(phylo$tip.label)
str(n1)
bark2 <- bark[bark$Species %in% n1,]
dim(bark)
dim(bark2)
length(unique(bark2$Species)) #only 27, less than the tree
#so, second reduce tree to match common taxa with data
n2<-unique(bark2$Species)
phylo2<-keep.tip(phylo,phylo$tip.label[match(n2, phylo$tip.label)])
summary(phylo2) #now 27 tips, which match the ones you made above
#make the covariance matrix from the phylogeny
phylo_cor <- ape::vcv.phylo(phylo2)
summary(phylo_cor)
dim(phylo_cor)
#make an additional factor to reference the species in the phylogeny
bark2$phylo2 <- bark2$Species
summary(bark2)
#Distribution
par(mfrow=c(1,3))
plot(density((bark2$D)))
plot(density(sqrt(bark2$D)))
plot(density(log(bark2$D)))
bark2 $Dlog=log(bark2 $D)
summary(bark2)
#take a look at what it says about the function
?brm
#lets run the model using
set.seed(1)
model_Flog <-brm(Dlog~Function+(1|phylo2)+(1|Species),
cov_ranef = list(phylo2 = phylo_cor),
data = bark2, family = gaussian(link="identity"), sample_prior = TRUE,
iter = 10000,warmup = 5000, chains = 4, cores = 4,
thin = 10, save_all_pars = TRUE,seed=T,
control=list(adapt_delta=0.99))
#use summary() to check convergence of the model (Rhat and ESS) and the parameter estimates (coefficients and betas)
summary(model_Flog)
#now look at the posterior distributions generated for each estimate and the chain value (this should form nice horizontal bands called "hairy caterpillars"; if not flat then sampling possibly insufficient or model underspecified)
plot(model_Flog, N = 6, ask = FALSE)
#plot the posterior fixed effect estimates with credible intervals over the data
plot(conditional_effects(model_Flog), points = TRUE)
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(model_Flog, pars = c("^b_", "^sd_"))
#estimate proportional variation explained by phylogenetic signal
hyp <- "(sd_phylo2__Intercept^2)/ (sd_phylo2__Intercept^2 + sd_Species__Intercept^2 + sigma^2) = 0"
(hyp <- hypothesis(model_Flog, hyp, class = NULL))
#R-squared: variance explained by model
bayes_R2(model_Flog)
#output table including conditional and marginal R2
library(sjPlot)
tab_model(model_Flog, show.intercept = T, show.r2 = TRUE,
transform = NULL,show.re.var=T)
pp_check(model_Flog, nsamples =100)
#what follows are some tests evaluating the performance of the analysis
#library(performance)
#Posterior predictive distribution: good data fitting
brms::pp_check(model_Flog, nsamples =100)
#Posterior predictive intervals: good data fitting
pp_check(model_Flog, type = "intervals_grouped", group = "Function")
#Posterior predictive fit: good data fitting
pp_check(model_Flog, type = "scatter_avg_grouped", group = "Function") +
geom_abline(intercept = 0, slope = 1 , color = "red", lty = 2)
#plot the posterior fixed effect estimates with credible intervals over the data
plot(conditional_effects(model_Flog), points = TRUE)
#Posterior estimates and confidence intervals: tests of significance
mcmc_plot(model_Flog)
####Model selection
#Leave-one-out cross-validation: compare models performance
loo(model_Flog,model_Flog2)
